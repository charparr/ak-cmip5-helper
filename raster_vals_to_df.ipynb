{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b74b643d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import pandas as pd\n",
    "import rasterio as rio\n",
    "import numpy as np\n",
    "import pickle\n",
    "import glob\n",
    "from rasterio.windows import Window\n",
    "from pyproj import Transformer\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8d54c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_list = pd.read_json(\"./first_order_station_data/first-order-stations.json\")\n",
    "station_list.set_index(\"station\", inplace=True)\n",
    "station_data_fps = [x for x in Path(\"./first_order_station_data/\").rglob(\"*.csv\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aef417e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmip5_path = Path(\"/atlas_scratch/cparr4/backtest/gcms\")\n",
    "years = [str(x) for x in range(2006, 2023)]\n",
    "gcms = [\"5ModelAvg\", \"GFDL-CM3\", \"GISS-E2-R\", \"IPSL-CM5A-LR\", \"MRI-CGCM3\", \"CCSM4\"]\n",
    "rcps = [\"rcp45\", \"rcp60\", \"rcp85\"]\n",
    "clim_vars = [\"pr_total_mm\", \"tas_mean_C\"]\n",
    "\n",
    "cmip5_fps = [x for x in Path(cmip5_path).rglob(\"*.tif\") if x.name.split(\"_\")[-1][:-4] in years]\n",
    "\n",
    "with rio.open(cmip5_fps[0]) as src:\n",
    "    tif_crs = src.crs\n",
    "    transformer = Transformer.from_crs(\"epsg:4326\", tif_crs)\n",
    "\n",
    "assert len(cmip5_fps) == len(years) * len(gcms) * len(rcps) * len(clim_vars) * 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fc09a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_model(geotiff_path):\n",
    "    return [x for x in gcms if x.lower() in geotiff_path.name.lower()][0]\n",
    "\n",
    "\n",
    "def parse_scenario(geotiff_path):\n",
    "    return [x for x in rcps if x.lower() in geotiff_path.name.lower()][0]\n",
    "\n",
    "\n",
    "def parse_clim_var(geotiff_path):\n",
    "    return [x for x in clim_vars if x.lower() in geotiff_path.name.lower()][0]\n",
    "\n",
    "\n",
    "def transform_lat_lon(lat, lon):\n",
    "    yx_3338 = transformer.transform(lat, lon)\n",
    "    return yx_3338"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b432183a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_point_value(geotiff_path, point):\n",
    "    with rio.open(geotiff_path) as src:\n",
    "        \n",
    "        y, x = point\n",
    "        row, col = src.index(y, x)\n",
    "        \n",
    "        window = Window(col, row, 1, 1)\n",
    "        arr = src.read(1, window=window)\n",
    "\n",
    "        year = geotiff_path.name.split(\"_\")[-1][:-4]\n",
    "        mo = geotiff_path.name.split(\"_\")[-2]\n",
    "        mo_year = f\"{mo}-{year}\"\n",
    "        \n",
    "        model = parse_model(geotiff_path)\n",
    "        scenario = parse_scenario(geotiff_path)\n",
    "        climate_variable = parse_clim_var(geotiff_path)\n",
    "\n",
    "        return mo_year, model, scenario, climate_variable, arr[0]\n",
    "\n",
    "\n",
    "def extract_point_values(geotiff_paths, points):\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=32) as executor:\n",
    "        # Use tqdm to create a progress bar\n",
    "        with tqdm(total=len(geotiff_paths)) as pbar:\n",
    "            # Map the extract_point_value function over the list of geotiff_paths and points\n",
    "            results = []\n",
    "            for result in executor.map(extract_point_value, geotiff_paths, points):\n",
    "                results.append(result)\n",
    "                pbar.update()\n",
    "    del executor\n",
    "\n",
    "    # Create a Pandas DataFrame from the results\n",
    "    df = pd.DataFrame(results, columns=['date', 'model', 'scenario', 'variable', 'value'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "548a7d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_data(flat_df):\n",
    "    groups = flat_df.groupby(['model', 'scenario', \"variable\", 'date'])[\"value\"].apply(float)\n",
    "    return groups.to_frame().sort_values(['model', 'scenario', 'variable', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14a5d55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta Junction number of pr NaN values: 7\n",
      "Replacing NaNs with mean values...\n",
      "Utqiaġvik number of pr NaN values: 2\n",
      "Replacing NaNs with mean values...\n",
      "All NaN values have been replaced with mean values.\n"
     ]
    }
   ],
   "source": [
    "di = {}\n",
    "for fp in station_data_fps:\n",
    "    station_id = fp.name.split(\"_\")[1]\n",
    "    station_name = station_list.loc[station_id][\"name\"]\n",
    "    di[station_name] = {}\n",
    "    \n",
    "    di[station_name][\"lat\"] = round(station_list.loc[station_id][\"latitude\"], 4)\n",
    "    di[station_name][\"lon\"] = round(station_list.loc[station_id][\"longitude\"], 4)\n",
    "    di[station_name][\"point_3338\"] = transform_lat_lon(di[station_name][\"lat\"], di[station_name][\"lon\"])\n",
    "    \n",
    "    di[station_name][\"ID\"] = station_id\n",
    "    station_df = pd.read_csv(fp, header=4)\n",
    "    # observed units are inches precip, degrees F\n",
    "    di[station_name][\"total_precip_observed_mm\"] = station_df[\"Monthly Total Precipitation (in)\"].values * 25.4\n",
    "    di[station_name][\"tasmean_observed_C\"] = (station_df[\"Monthly Average Mean Temperature (degF)\"].values - 32) * (5/9)\n",
    "    \n",
    "    # check for nan values\n",
    "    pr_nan_count = np.isnan(di[station_name][\"total_precip_observed_mm\"]).sum()\n",
    "    tasmean_nan_count = np.isnan(di[station_name][\"tasmean_observed_C\"]).sum()\n",
    "    \n",
    "    # Print the count of NaN values\n",
    "    if pr_nan_count != 0:\n",
    "        print(f\"{station_name} number of pr NaN values: {pr_nan_count}\")\n",
    "        print(\"Replacing NaNs with mean values...\")\n",
    "\n",
    "    if tasmean_nan_count != 0:\n",
    "        print(f\"{station_name} number of tasmean NaN values: {tasmean_nan_count}\")\n",
    "        print(\"Replacing NaNs with mean values...\")\n",
    "\n",
    "    # replace nan values with the mean of the observations\n",
    "    pr_mean = np.nanmean(di[station_name][\"total_precip_observed_mm\"])\n",
    "    tasmean_mean = np.nanmean(di[station_name][\"tasmean_observed_C\"])\n",
    " \n",
    "    # Create a Boolean mask indicating which elements are NaN\n",
    "    pr_mask = np.isnan(di[station_name][\"total_precip_observed_mm\"])\n",
    "    tasmean_mask = np.isnan(di[station_name][\"tasmean_observed_C\"])\n",
    "    \n",
    "    # Replace the NaN values with the mean\n",
    "    pr_clean = np.where(pr_mask, pr_mean, di[station_name][\"total_precip_observed_mm\"])\n",
    "    tasmean_clean = np.where(tasmean_mask, tasmean_mean, di[station_name][\"tasmean_observed_C\"])\n",
    "    \n",
    "    di[station_name][\"pr_total_mm\"] = pr_clean\n",
    "    di[station_name][\"tas_mean_C\"] = tasmean_clean\n",
    "    \n",
    "    # Verify the values were replaced\n",
    "    pr_nan_count = np.isnan(di[station_name][\"pr_total_mm\"]).sum()\n",
    "    tasmean_nan_count = np.isnan(di[station_name][\"tas_mean_C\"]).sum()\n",
    "    assert(pr_nan_count + tasmean_nan_count == 0)\n",
    "    # pop the observational data that wasn't clean\n",
    "    di[station_name].pop(\"total_precip_observed_mm\")\n",
    "    di[station_name].pop(\"tasmean_observed_C\")\n",
    "print(\"All NaN values have been replaced with mean values.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "714400e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Juneau...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7344/7344 [00:10<00:00, 715.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Juneau Complete.\n",
      "Processing Ketchikan...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7344/7344 [00:07<00:00, 935.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Ketchikan Complete.\n",
      "Processing Kodiak...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7344/7344 [00:07<00:00, 1027.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Kodiak Complete.\n",
      "Processing King Salmon...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7344/7344 [00:06<00:00, 1133.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing King Salmon Complete.\n",
      "Processing Fairbanks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7344/7344 [00:07<00:00, 1003.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Fairbanks Complete.\n",
      "Processing Delta Junction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7344/7344 [00:07<00:00, 1045.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Delta Junction Complete.\n",
      "Processing Anchorage...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7344/7344 [00:05<00:00, 1230.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Anchorage Complete.\n",
      "Processing Nome...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7344/7344 [00:07<00:00, 944.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Nome Complete.\n",
      "Processing Utqiaġvik...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7344/7344 [00:06<00:00, 1086.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Utqiaġvik Complete.\n"
     ]
    }
   ],
   "source": [
    "for k in di.keys():\n",
    "    print(f\"Processing {k}...\")\n",
    "    df = group_data(extract_point_values(cmip5_fps, [di[k][\"point_3338\"]] * len(cmip5_fps)))\n",
    "    di[k][\"extracted_data\"] = df\n",
    "    del df\n",
    "    print(f\"Processing {k} Complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e8c534",
   "metadata": {},
   "source": [
    "# Nine Point Extractions from 7000+ GeoTIFFs: pretty fast!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c53f9460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the date index a proper DatetimeIndex\n",
    "for k in di.keys():\n",
    "    di[k][\"extracted_data\"].reset_index(inplace=True, level = [\"model\", \"scenario\", \"variable\"])\n",
    "    di[k][\"extracted_data\"].set_index(pd.DatetimeIndex(di[k][\"extracted_data\"].index), inplace=True)\n",
    "    groups = di[k][\"extracted_data\"].groupby(['model', 'scenario', \"variable\", \"date\"])[\"value\"].apply(float)\n",
    "    di[k][\"extracted_data\"] = groups.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a783494a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('extracted_data/ak_station_extractions.pickle', 'wb') as handle:\n",
    "    pickle.dump(di, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f826a39f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th>scenario</th>\n",
       "      <th>variable</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">5ModelAvg</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">rcp45</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">pr_total_mm</th>\n",
       "      <th>2006-01-01</th>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-02-01</th>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-03-01</th>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-04-01</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-05-01</th>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">MRI-CGCM3</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">rcp85</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">tas_mean_C</th>\n",
       "      <th>2022-08-01</th>\n",
       "      <td>13.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-01</th>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-01</th>\n",
       "      <td>-0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-01</th>\n",
       "      <td>-22.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-01</th>\n",
       "      <td>-18.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7344 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           value\n",
       "model     scenario variable    date             \n",
       "5ModelAvg rcp45    pr_total_mm 2006-01-01   10.0\n",
       "                               2006-02-01   13.0\n",
       "                               2006-03-01   14.0\n",
       "                               2006-04-01    4.0\n",
       "                               2006-05-01   13.0\n",
       "...                                          ...\n",
       "MRI-CGCM3 rcp85    tas_mean_C  2022-08-01   13.5\n",
       "                               2022-09-01    8.9\n",
       "                               2022-10-01   -0.9\n",
       "                               2022-11-01  -22.6\n",
       "                               2022-12-01  -18.1\n",
       "\n",
       "[7344 rows x 1 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "di[\"Fairbanks\"][\"extracted_data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817d2679",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
